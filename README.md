# Databricks Learning Journey ğŸš€  
#DatabricksWithIDC  

This repository documents my daily learning and hands-on practice with Databricks, Spark, and modern data engineering concepts.

---

## ğŸ“… DAY 1 (09/01/26) â€“ Platform Setup & First Steps

### ğŸ“˜ Topics Learned
- Why Databricks over Pandas & Hadoop
- Lakehouse architecture fundamentals
- Databricks workspace structure
- Industry use cases (Netflix, Shell, Comcast)

### ğŸ› ï¸ Hands-on Tasks
- Created Databricks Community Edition (free) account
- Explored Workspace, Compute, and Data Explorer
- Created first Databricks notebook
- Executed basic PySpark commands

### ğŸ”‘ Key Takeaways
- **Databricks over Pandas & Hadoop:** Databricks addresses limitations of Pandas and Hadoop in following ways:
  
   -Enabling distributed, in-memory processing for large datasets
      
   -Providing faster execution compared to MapReduce
      
   -Supporting multiple languages (Python, SQL, Scala, R)
      
   -Offering an integrated platform for data engineering, analytics, and machine learning
      
   -Simplifying cluster management and collaboration
  
- Lakehouse combines flexibility of data lakes with reliability of warehouses
  
- PySpark enables distributed data processing with minimal setup

### ğŸ“ Practice
Basic PySpark DataFrame creation and filtering.  
ğŸ“‚ Code: `Days Learning/Day 1/Pyspark_practice.ipynb`

### ğŸ”– Tags
#DatabricksWithIDC  
@Databricks @Codebasics @Indiandataclub


